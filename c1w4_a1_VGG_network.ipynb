{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c1w4_a1_VGG network.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgJECu3zai1w0N8YxEcx5D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Loga19818eeanvesh/TensorFlow_DeepLearning_Assignments/blob/main/c1w4_a1_VGG_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90v4-8CzeV2F",
        "outputId": "b0b22de9-8649-4e8f-8918-d0d3f7d6c35c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.2.0\n",
            "  Downloading tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2 MB 3.7 kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
            "\u001b[K     |████████████████████████████████| 454 kB 38.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 39.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.43.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.13.3)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 41.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.21.5)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, h5py, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.2.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Flatten,  Activation , Conv2D , BatchNormalization , Add , MaxPool2D , GlobalAveragePooling2D , Dense\n",
        "import tensorflow_datasets as tfds\n",
        "print(\"Version of tensorflow is : \",tf.__version__)\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsEmL_q4eqar",
        "outputId": "20062267-138e-4537-e9b4-04b3494b4561"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version of tensorflow is :  2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class sub_model(Model):\n",
        "  def __init__(self,filters,noof_layers):\n",
        "    super(sub_model , self ).__init__(name  ='')\n",
        "    self.noof_layers = noof_layers\n",
        "    self.filters = filters\n",
        "    self.conv2d = Conv2D(filters , 3 , activation='relu')\n",
        "    self.pool  = MaxPool2D((2,2))\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = self.conv2d(inputs)\n",
        "    for i in range(1,self.noof_layers):\n",
        "      x = Conv2D(self.filters , 3 , activation='relu')(x)\n",
        "    x = self.pool(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ORSHsE3hes5x"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG_Net(Model):\n",
        "  def __init__(self,num_classes , activation = 'softmax'):\n",
        "    super(VGG_Net, self).__init__(name=\"\")\n",
        "    self.block1 = sub_model(filters=64,noof_layers=2)\n",
        "    self.block2 = sub_model(filters=128,noof_layers=2)\n",
        "    self.block3 = sub_model(filters=256,noof_layers=3)\n",
        "    self.block4 = sub_model(filters=512,noof_layers=3)\n",
        "    self.block5 = sub_model(filters=512,noof_layers=3)\n",
        "    self.flatten = Flatten()\n",
        "    self.dense1 = Dense(units=4096,activation='relu')\n",
        "    self.dense2 = Dense(units=4096,activation='relu')\n",
        "    self.classifier =  Dense(num_classes , activation = tf.keras.activations.get(activation))\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = self.block1(inputs)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.block4(x)\n",
        "    x = self.block5(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.dense2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "jjD60DGlh_bk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\n",
        "        super(Block, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.repetitions = repetitions\n",
        "        conv2d_layers = {}\n",
        "        # Define a conv2D_0, conv2D_1, etc based on the number of repetitions\n",
        "        for i in range(self.repetitions):\n",
        "            \n",
        "            # Define a Conv2D layer, specifying filters, kernel_size, activation and padding.\n",
        "            conv2d_layers[f'conv2D_{i}'] = tf.keras.layers.Conv2D(self.filters, self.kernel_size,\n",
        "                                                               activation= 'relu', padding= 'same')\n",
        "        self.conv2d_layers = conv2d_layers\n",
        "        # Define the max pool layer that will be added after the Conv2D blocks\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size, strides=strides)\n",
        "  \n",
        "    def call(self, inputs):\n",
        "        # access the class's conv2D_0 layer\n",
        "        x = self.conv2d_layers['conv2D_0'](inputs)\n",
        "\n",
        "        # for the remaining conv2D_i layers from 1 to `repetitions` they will be connected to the previous layer\n",
        "        for i in range(1,self.repetitions):\n",
        "            # access conv2D_i by formatting the integer `i`. (hint: check how these were saved using `vars()` earlier)\n",
        "            x = self.conv2d_layers[f'conv2D_{i}'](x)\n",
        "\n",
        "        # Finally, add the max_pool layer\n",
        "        max_pool = self.max_pool(x)\n",
        "      \n",
        "        return max_pool\n"
      ],
      "metadata": {
        "id": "CO-O3bOTsf2z"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyVGG(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super(MyVGG, self).__init__()\n",
        "\n",
        "        # Creating blocks of VGG with the following \n",
        "        # (filters, kernel_size, repetitions) configurations\n",
        "        self.block_a = Block(filters=64, kernel_size=3, repetitions=2)\n",
        "        self.block_b = Block(filters=128, kernel_size=3, repetitions=2)\n",
        "        self.block_c = Block(filters=256, kernel_size=3, repetitions=3)\n",
        "        self.block_d = Block(filters=512, kernel_size=3, repetitions=3)\n",
        "        self.block_e = Block(filters=512, kernel_size=3, repetitions=3)\n",
        "\n",
        "        # Classification head\n",
        "        # Define a Flatten layer\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        # Create a Dense layer with 256 units and ReLU as the activation function\n",
        "        self.fc = tf.keras.layers.Dense(256, activation='relu')\n",
        "        # Finally add the softmax classifier using a Dense layer\n",
        "        self.classifier =tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Chain all the layers one after the other\n",
        "        x = self.block_a(inputs)\n",
        "        x = self.block_b(x)\n",
        "        x = self.block_c(x)\n",
        "        x = self.block_d(x)\n",
        "        x = self.block_e(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Cimsj8GBsjm_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vggnet_model = MyVGG(num_classes=2)"
      ],
      "metadata": {
        "id": "zv9nr8InkzIb"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vggnet_model.compile(optimizer='adam' ,loss='sparse_categorical_crossentropy' , metrics=['acc'])"
      ],
      "metadata": {
        "id": "16qWVJHpmX-d"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN, data_dir='data/')"
      ],
      "metadata": {
        "id": "2VudROPxm4It"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(features):\n",
        "    # Resize and normalize\n",
        "    image = tf.image.resize(features['image'], (224, 224))\n",
        "    return tf.cast(image, tf.float32) / 255., features['label']\n",
        "\n",
        "# Apply transformations to dataset\n",
        "dataset = dataset.map(preprocess).batch(32)\n"
      ],
      "metadata": {
        "id": "g3tZY6wpnBC6"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = vggnet_model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "id": "7nu2vcDSnGyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vggnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBqYAIWkuykI",
        "outputId": "b6ec020f-87d4-4ec5-bbee-e35cbf95b6e9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_vgg\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block (Block)                multiple                  38720     \n",
            "_________________________________________________________________\n",
            "block_1 (Block)              multiple                  221440    \n",
            "_________________________________________________________________\n",
            "block_2 (Block)              multiple                  1475328   \n",
            "_________________________________________________________________\n",
            "block_3 (Block)              multiple                  5899776   \n",
            "_________________________________________________________________\n",
            "block_4 (Block)              multiple                  7079424   \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             multiple                  6422784   \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             multiple                  514       \n",
            "=================================================================\n",
            "Total params: 21,137,986\n",
            "Trainable params: 21,137,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(vggnet_model , to_file = \"vggnet.png\" , show_shapes = True , show_layer_names = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "uRd9a6aAu8E0",
        "outputId": "d8b3f20e-eee3-4c4b-bc88-77763ff2cb18"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAAA8CAIAAAD5dEPdAAAABmJLR0QA/wD/AP+gvaeTAAAE+0lEQVR4nO2bSyh8XxzAv/MyY2KGlNmY8ShihyJkgWaBKGUYWSmPKGmGZiELG8rK2EyKX+TVjFcZsUOhvPKK5FFmI1KEicG4V/e/OHW7P6N7ZjS/+fn7nc/K93zP637mnDPXdQkYhgECL8K/PYH/AcQRHuIID3GER8wN1tfXu7u7/9ZUvg+ZmZnNzc1s+Ns6uri4mJqaCviUvhcbGxvr6+vcErFnpcnJyUDN5ztSVlb2oYScR3iIIzzEER7iCA9xhIc4wkMc4SGO8BBHeIgjPMQRHuIID3GEhzjCQxzhIY7wEEd4fo4jhmEmJyf7+vq+kMV3zTI+Pv6hxBOz2SyXywUCQWpqamRkpFgslsvlKSkp2dnZUVFRUqlUqVSaTCZUubq6Go0SFxe3u7vLMExVVVVwcLBCobDb7fwDJSYmAgAayOVyMQxjMpkUCoVUKh0cHGQYhqbpzs7OhIQEmUwWERERHR2dnJx8f3+PmvNnedDpdDqdjlvisyOGYdrb2wFgc3PT5XLd3t7m5+cDwPz8/M3NjcvlampqAoD9/X1UubS0VCQSXV5ess0rKytnZ2exo9A0HRMTo9FoaJpmC41Go9lsRj93dnaKRCK73f78/Lyzs6NSqXJyctia/Fke/Ono8fERhUNDQwBweHiIwq2tLQCw2WwoXFhYAICOjg4UOp3O+Ph47mXzYDabAWBiYgKFLpdLo9E4nU4UpqWlpaens5Xr6uqEQqHb7fYmy4OnIz+cR0FBQQBA0zQKJRIJAFAUhcK8vLyEhISBgQGGYZC7iooKkUjkTc81NTVKpbKnpweFo6OjJSUlCoUCha+vrwznhY7393eJRML2zJ/1iT9+ZgsEgvr6eofDsbi4CADDw8PsIYUlJCSkrq5ubW0Nrc3e3l60kRGFhYU7Ozt2u/3l5WV7e3tmZqaoqIi1wJ/1De6i+tpes1qtALC3t4fCvb09ABgZGWHr393dyWQyvV5/cnJSUFCA7Z/LxcWFRCKpqKhYXl4uLi7mpl5eXrRabVhYmFgsVqvVDQ0Nd3d3XmZ58Nxrn/wN0u+Eh4fr9XqbzRYaGlpbW+tT26ioqPLy8vHx8aurK/TZsBwdHZ2fn9/c3IjFn1wFf9YnAnR/1NDQ4Ha75+bmiouLfW3b0tJC0/T9/X1eXh63vLGxUaPRPD09fdqKP+sb3EXlzV7r6emRy+UAEBMTs7q62tXVpVQqAUClUo2NjdlsNpVKBQDh4eFWq5XbMCUlpbW11ZvV7klubu6vX78+FC4tLUVERLAXIpFIkpKSpqenvcny4J/v/q9RWFjocDj82KHFYjEYDGzodruNRqNUKn1+fsZmeQj0eURRFLoVODg4kMlksbGx/ur5+vq6qalpf3+fLQkKCtJoNBRFURTldDp5ssHBwb4NxhXm93VkNBrPzs5OT09TU1OPjo64qePjY55Z6fV6/p4fHh5kMpnBYLi+vn57e7u8vOzv7w8NDa2srMRm+Qn0XmtraxMKhWq12ptfPnxlZWVFq9UqFAqRSKRUKrOysiwWC0VR3mR58HQkYDg3oxMTE+gD9G0p/izQ+0fcl7B+zrORPwdxhIc4wkMc4SGO8BBHeIgjPMQRHuIID3GEhzjCQxzhIY7wfPKMzfMfb/4pNjY2MjIyuCW/rSO1Wq3T6QI7pW9HRkZGZmYmt0Twjz8t8gZyHuEhjvAQR3iIIzz/AUMV7MHhdSEtAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}