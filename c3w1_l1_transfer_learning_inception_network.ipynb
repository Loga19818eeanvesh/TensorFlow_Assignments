{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "c3w1_l1_transfer_learning_inception_network.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZxXMmAdHKOdJDFTLn/mMK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Loga19818eeanvesh/TensorFlow_DeepLearning_Assignments/blob/main/c3w1_l1_transfer_learning_inception_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9205nUb3ePNp"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from shutil import copyfile\n",
        "\n",
        "\n",
        "data_url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
        "data_file_name = \"catsdogs.zip\"\n",
        "download_dir = '/tmp/'\n",
        "urllib.request.urlretrieve(data_url, data_file_name)\n",
        "zip_ref = zipfile.ZipFile(data_file_name, 'r')\n",
        "zip_ref.extractall(download_dir)\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of cat images:\",len(os.listdir('/tmp/PetImages/Cat/')))\n",
        "print(\"Number of dog images:\", len(os.listdir('/tmp/PetImages/Dog/')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb0nYaO7eeBO",
        "outputId": "c265de77-4e50-49fd-cfd8-875b40a895ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cat images: 12501\n",
            "Number of dog images: 12501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    os.mkdir('/tmp/cats-v-dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
        "    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
        "except OSError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "WPHWdIxuegxy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from shutil import copyfile\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = SOURCE + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[:testing_length]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TRAINING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TESTING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh3AmlSTeuQo",
        "outputId": "4ec6067e-2050-467d-dbd2-b2937850ecb0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "666.jpg is zero length, so ignoring.\n",
            "11702.jpg is zero length, so ignoring.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of training cat images\", len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
        "print(\"Number of training dog images\", len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
        "print(\"Number of testing cat images\", len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
        "print(\"Number of testing dog images\", len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T3t5h3NezL9",
        "outputId": "47155df2-7228-4a6f-d14e-3cd6743574c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training cat images 11250\n",
            "Number of training dog images 11250\n",
            "Number of testing cat images 1250\n",
            "Number of testing dog images 1250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                                    batch_size=100,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "VALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\"\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                                              batch_size=100,\n",
        "                                                              class_mode='binary',\n",
        "                                                              target_size=(150, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k99sHmpce2_C",
        "outputId": "c2ed92f4-009e-4ecb-bec2-8cca5508ef67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22499 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "weights_file = \"inception_v3.h5\"\n",
        "urllib.request.urlretrieve(weights_url, weights_file)\n",
        "\n",
        "# Instantiate the model\n",
        "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
        "                                include_top=False,\n",
        "                                weights=None)\n",
        "\n",
        "# load pre-trained weights\n",
        "pre_trained_model.load_weights(weights_file)\n",
        "\n",
        "# freeze the layers\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x-3gbtDfHCB",
        "outputId": "87322c89-a1a8-4865-97ce-ff81b99b069f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "    print(layer.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8In8tGV_f5eK",
        "outputId": "db6c3d83-4993-429d-db80-d66a5382a43e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1\n",
            "conv2d\n",
            "batch_normalization\n",
            "activation\n",
            "conv2d_1\n",
            "batch_normalization_1\n",
            "activation_1\n",
            "conv2d_2\n",
            "batch_normalization_2\n",
            "activation_2\n",
            "max_pooling2d\n",
            "conv2d_3\n",
            "batch_normalization_3\n",
            "activation_3\n",
            "conv2d_4\n",
            "batch_normalization_4\n",
            "activation_4\n",
            "max_pooling2d_1\n",
            "conv2d_8\n",
            "batch_normalization_8\n",
            "activation_8\n",
            "conv2d_6\n",
            "conv2d_9\n",
            "batch_normalization_6\n",
            "batch_normalization_9\n",
            "activation_6\n",
            "activation_9\n",
            "average_pooling2d\n",
            "conv2d_5\n",
            "conv2d_7\n",
            "conv2d_10\n",
            "conv2d_11\n",
            "batch_normalization_5\n",
            "batch_normalization_7\n",
            "batch_normalization_10\n",
            "batch_normalization_11\n",
            "activation_5\n",
            "activation_7\n",
            "activation_10\n",
            "activation_11\n",
            "mixed0\n",
            "conv2d_15\n",
            "batch_normalization_15\n",
            "activation_15\n",
            "conv2d_13\n",
            "conv2d_16\n",
            "batch_normalization_13\n",
            "batch_normalization_16\n",
            "activation_13\n",
            "activation_16\n",
            "average_pooling2d_1\n",
            "conv2d_12\n",
            "conv2d_14\n",
            "conv2d_17\n",
            "conv2d_18\n",
            "batch_normalization_12\n",
            "batch_normalization_14\n",
            "batch_normalization_17\n",
            "batch_normalization_18\n",
            "activation_12\n",
            "activation_14\n",
            "activation_17\n",
            "activation_18\n",
            "mixed1\n",
            "conv2d_22\n",
            "batch_normalization_22\n",
            "activation_22\n",
            "conv2d_20\n",
            "conv2d_23\n",
            "batch_normalization_20\n",
            "batch_normalization_23\n",
            "activation_20\n",
            "activation_23\n",
            "average_pooling2d_2\n",
            "conv2d_19\n",
            "conv2d_21\n",
            "conv2d_24\n",
            "conv2d_25\n",
            "batch_normalization_19\n",
            "batch_normalization_21\n",
            "batch_normalization_24\n",
            "batch_normalization_25\n",
            "activation_19\n",
            "activation_21\n",
            "activation_24\n",
            "activation_25\n",
            "mixed2\n",
            "conv2d_27\n",
            "batch_normalization_27\n",
            "activation_27\n",
            "conv2d_28\n",
            "batch_normalization_28\n",
            "activation_28\n",
            "conv2d_26\n",
            "conv2d_29\n",
            "batch_normalization_26\n",
            "batch_normalization_29\n",
            "activation_26\n",
            "activation_29\n",
            "max_pooling2d_2\n",
            "mixed3\n",
            "conv2d_34\n",
            "batch_normalization_34\n",
            "activation_34\n",
            "conv2d_35\n",
            "batch_normalization_35\n",
            "activation_35\n",
            "conv2d_31\n",
            "conv2d_36\n",
            "batch_normalization_31\n",
            "batch_normalization_36\n",
            "activation_31\n",
            "activation_36\n",
            "conv2d_32\n",
            "conv2d_37\n",
            "batch_normalization_32\n",
            "batch_normalization_37\n",
            "activation_32\n",
            "activation_37\n",
            "average_pooling2d_3\n",
            "conv2d_30\n",
            "conv2d_33\n",
            "conv2d_38\n",
            "conv2d_39\n",
            "batch_normalization_30\n",
            "batch_normalization_33\n",
            "batch_normalization_38\n",
            "batch_normalization_39\n",
            "activation_30\n",
            "activation_33\n",
            "activation_38\n",
            "activation_39\n",
            "mixed4\n",
            "conv2d_44\n",
            "batch_normalization_44\n",
            "activation_44\n",
            "conv2d_45\n",
            "batch_normalization_45\n",
            "activation_45\n",
            "conv2d_41\n",
            "conv2d_46\n",
            "batch_normalization_41\n",
            "batch_normalization_46\n",
            "activation_41\n",
            "activation_46\n",
            "conv2d_42\n",
            "conv2d_47\n",
            "batch_normalization_42\n",
            "batch_normalization_47\n",
            "activation_42\n",
            "activation_47\n",
            "average_pooling2d_4\n",
            "conv2d_40\n",
            "conv2d_43\n",
            "conv2d_48\n",
            "conv2d_49\n",
            "batch_normalization_40\n",
            "batch_normalization_43\n",
            "batch_normalization_48\n",
            "batch_normalization_49\n",
            "activation_40\n",
            "activation_43\n",
            "activation_48\n",
            "activation_49\n",
            "mixed5\n",
            "conv2d_54\n",
            "batch_normalization_54\n",
            "activation_54\n",
            "conv2d_55\n",
            "batch_normalization_55\n",
            "activation_55\n",
            "conv2d_51\n",
            "conv2d_56\n",
            "batch_normalization_51\n",
            "batch_normalization_56\n",
            "activation_51\n",
            "activation_56\n",
            "conv2d_52\n",
            "conv2d_57\n",
            "batch_normalization_52\n",
            "batch_normalization_57\n",
            "activation_52\n",
            "activation_57\n",
            "average_pooling2d_5\n",
            "conv2d_50\n",
            "conv2d_53\n",
            "conv2d_58\n",
            "conv2d_59\n",
            "batch_normalization_50\n",
            "batch_normalization_53\n",
            "batch_normalization_58\n",
            "batch_normalization_59\n",
            "activation_50\n",
            "activation_53\n",
            "activation_58\n",
            "activation_59\n",
            "mixed6\n",
            "conv2d_64\n",
            "batch_normalization_64\n",
            "activation_64\n",
            "conv2d_65\n",
            "batch_normalization_65\n",
            "activation_65\n",
            "conv2d_61\n",
            "conv2d_66\n",
            "batch_normalization_61\n",
            "batch_normalization_66\n",
            "activation_61\n",
            "activation_66\n",
            "conv2d_62\n",
            "conv2d_67\n",
            "batch_normalization_62\n",
            "batch_normalization_67\n",
            "activation_62\n",
            "activation_67\n",
            "average_pooling2d_6\n",
            "conv2d_60\n",
            "conv2d_63\n",
            "conv2d_68\n",
            "conv2d_69\n",
            "batch_normalization_60\n",
            "batch_normalization_63\n",
            "batch_normalization_68\n",
            "batch_normalization_69\n",
            "activation_60\n",
            "activation_63\n",
            "activation_68\n",
            "activation_69\n",
            "mixed7\n",
            "conv2d_72\n",
            "batch_normalization_72\n",
            "activation_72\n",
            "conv2d_73\n",
            "batch_normalization_73\n",
            "activation_73\n",
            "conv2d_70\n",
            "conv2d_74\n",
            "batch_normalization_70\n",
            "batch_normalization_74\n",
            "activation_70\n",
            "activation_74\n",
            "conv2d_71\n",
            "conv2d_75\n",
            "batch_normalization_71\n",
            "batch_normalization_75\n",
            "activation_71\n",
            "activation_75\n",
            "max_pooling2d_3\n",
            "mixed8\n",
            "conv2d_80\n",
            "batch_normalization_80\n",
            "activation_80\n",
            "conv2d_77\n",
            "conv2d_81\n",
            "batch_normalization_77\n",
            "batch_normalization_81\n",
            "activation_77\n",
            "activation_81\n",
            "conv2d_78\n",
            "conv2d_79\n",
            "conv2d_82\n",
            "conv2d_83\n",
            "average_pooling2d_7\n",
            "conv2d_76\n",
            "batch_normalization_78\n",
            "batch_normalization_79\n",
            "batch_normalization_82\n",
            "batch_normalization_83\n",
            "conv2d_84\n",
            "batch_normalization_76\n",
            "activation_78\n",
            "activation_79\n",
            "activation_82\n",
            "activation_83\n",
            "batch_normalization_84\n",
            "activation_76\n",
            "mixed9_0\n",
            "concatenate\n",
            "activation_84\n",
            "mixed9\n",
            "conv2d_89\n",
            "batch_normalization_89\n",
            "activation_89\n",
            "conv2d_86\n",
            "conv2d_90\n",
            "batch_normalization_86\n",
            "batch_normalization_90\n",
            "activation_86\n",
            "activation_90\n",
            "conv2d_87\n",
            "conv2d_88\n",
            "conv2d_91\n",
            "conv2d_92\n",
            "average_pooling2d_8\n",
            "conv2d_85\n",
            "batch_normalization_87\n",
            "batch_normalization_88\n",
            "batch_normalization_91\n",
            "batch_normalization_92\n",
            "conv2d_93\n",
            "batch_normalization_85\n",
            "activation_87\n",
            "activation_88\n",
            "activation_91\n",
            "activation_92\n",
            "batch_normalization_93\n",
            "activation_85\n",
            "mixed9_1\n",
            "concatenate_1\n",
            "activation_93\n",
            "mixed10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)"
      ],
      "metadata": {
        "id": "ZFaieLr-gZhy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(optimizer=RMSprop(lr=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "# train the model (adjust the number of epochs from 1 to improve performance)\n",
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data=validation_generator,\n",
        "            epochs=2,\n",
        "            verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zeeLdixg8Ou",
        "outputId": "c28d4c31-c7be-45c0-88f5-5da49860a674"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "  5/225 [..............................] - ETA: 15:33 - loss: 1.6944 - acc: 0.6460"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 1021s 5s/step - loss: 0.2299 - acc: 0.9110 - val_loss: 0.0882 - val_acc: 0.9656\n",
            "Epoch 2/2\n",
            "225/225 [==============================] - 988s 4s/step - loss: 0.1492 - acc: 0.9392 - val_loss: 0.0838 - val_acc: 0.9672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "EH57JcZUhNCK",
        "outputId": "39c2a6d3-e860-42db-84de-d1d4457c61b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  image_tensor = np.vstack([x])\n",
        "  classes = model.predict(image_tensor)\n",
        "  print(classes)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a dog\")\n",
        "  else:\n",
        "    print(fn + \" is a cat\")"
      ],
      "metadata": {
        "id": "AH6rwSXvhOEo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}